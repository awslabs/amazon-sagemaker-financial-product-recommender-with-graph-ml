{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33c07978-9240-47c1-9692-3366ebff702b",
   "metadata": {},
   "source": [
    "# Preparing the trade data\n",
    "\n",
    "In this notebook we merge the datasets and prepare the list of aggregated trades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3b28ec-5f77-4deb-bb51-432d8a7a35af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import USER, ITEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d659d8c0-bef9-418f-be2a-1f65ba486d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'source_data/scrape_parsed.parquet'\n",
    "ciknames_path = 'source_data/cikmap.tab'\n",
    "cusips_path = 'source_data/cusips.tsv'\n",
    "output_path = 'trades.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a01fd58-7057-4290-abed-d1eb3a22d691",
   "metadata": {},
   "source": [
    "First we load the holdings data and convert dates to a proper date format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb40f4e-b43a-4cea-a549-73791984c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loading {input_path}...')\n",
    "df = pd.read_parquet(input_path)\n",
    "df['rdate'] = pd.to_datetime(df.rdate, format='%Y%m%d')\n",
    "df['fdate'] = pd.to_datetime(df.fdate, format='%Y%m%d')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9fc693-7452-4a06-9fb7-3760601108af",
   "metadata": {},
   "source": [
    "Next we load the CIK (investor identifier) data, and map each CIK to the last name they have been using (some investors changed name while keeping the same CIK)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bbe1b6-efc7-4c35-9893-2ec9cba004c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ciknames = pd.read_csv(ciknames_path, sep='\\t')\n",
    "ciknames_prepared = ciknames.groupby('cik', as_index=False)['cikname'].apply(lambda z: list(z)[-1])\n",
    "ciknames_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b9b8b7-fd0a-41f5-a4b7-def28292dbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ciknames_prepared.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3daf178-164e-4873-bbf8-29517dbf0796",
   "metadata": {},
   "source": [
    "Now we join the holdings data to the CIK data and the CUSIP data in order to get investor and security names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2264e5b-7833-4207-b4fb-ffa56e7d438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, ciknames_prepared, 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec00601b-4984-445f-8a3d-86422dd1ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cusipnames = pd.read_csv(cusips_path, sep='\\t')\n",
    "df = pd.merge(df, cusipnames, 'left')\n",
    "df.cusipname.fillna(df.cusip, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace54604-b9db-4c5d-8924-4522b74c7018",
   "metadata": {},
   "source": [
    "Next we compute the aggregate trades. We consider that an aggregate trade is a new holding, a holding that is present in the current quarter and not in the previous quarter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3bae4f-8a4c-4548-bf73-26c9fbac17f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the set of securities for each investor and date\n",
    "df_groups = df.groupby(['cikname', 'rdate'])['cusipname'].apply(set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a2ca76-243a-4d9c-94fd-3cf4b071e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the new securities for each investor and date\n",
    "diff_data = []\n",
    "for cikname in tqdm(df.cikname.unique()):\n",
    "    g = df_groups[cikname]\n",
    "    for i, s in enumerate(g):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        assert g.index[i] > g.index[i-1], 'dates should be ascending' \n",
    "        s0 = g.iloc[i-1]\n",
    "        diff = s - s0\n",
    "        for cusip in diff:\n",
    "            diff_data.append([cikname, cusip, g.index[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc8381-a208-42d9-8daf-c656748ceb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the data in a dataframe\n",
    "df_diff = pd.DataFrame(diff_data, columns=['cikname', 'cusipname', 'rdate'])\n",
    "df_diff = df_diff.sort_values(['rdate', 'cikname', 'cusipname']).reset_index(drop=True)\n",
    "df_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e29ad5-e0ac-488e-8969-8d306756f1d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we create the final columns and save the file as 'trades.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb15214-7aa9-4963-9cc5-f6e645512eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff[USER] = df_diff.cikname\n",
    "df_diff[ITEM] = df_diff.cusipname\n",
    "df_diff['date'] = pd.to_datetime(df_diff.rdate, format='%Y%m%d')\n",
    "df_diff['trade'] = 1 # Just to facilitate analytics\n",
    "print(f'Saving to {output_path}...')\n",
    "df_diff[['date', 'trade', USER, ITEM]].to_csv(output_path, index=False, sep='\\t')\n",
    "!head {output_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa28d1f-86c4-4d6b-b186-73ade3e95bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
